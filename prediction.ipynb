{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T22:18:19.598336Z",
     "start_time": "2025-06-06T22:18:19.588297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, f1_score, classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.base import clone"
   ],
   "id": "cff6670ef9259128",
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T22:19:16.343786Z",
     "start_time": "2025-06-06T22:19:16.322264Z"
    }
   },
   "source": [
    "def preprocess_data(app_data, prev_app):\n",
    "    app_data_clean = app_data.copy()\n",
    "    prev_clean = prev_app.copy()\n",
    "\n",
    "    def cap_outliers(df, columns, threshold=3.5):\n",
    "        for col in columns:\n",
    "            if df[col].dtype in ['int64', 'float64']:\n",
    "                median = df[col].median()\n",
    "                mad = 1.4826 * np.median(np.abs(df[col] - median))\n",
    "                lower = median - threshold * mad\n",
    "                upper = median + threshold * mad\n",
    "                df[col] = np.clip(df[col], lower, upper)\n",
    "        return df\n",
    "\n",
    "    num_cols = app_data_clean.select_dtypes(include=['int64', 'float64']).columns\n",
    "    app_data_clean = cap_outliers(app_data_clean, num_cols)\n",
    "\n",
    "    # previous_application обработка\n",
    "    prev_clean['DAYS_DECISION'] = prev_clean['DAYS_DECISION'].abs()\n",
    "\n",
    "    financial_cols = ['AMT_APPLICATION', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE']\n",
    "    prev_clean = cap_outliers(prev_clean, financial_cols)\n",
    "\n",
    "    prev_clean['APP_CREDIT_RATIO'] = np.where(\n",
    "        prev_clean['AMT_CREDIT'] > 0,\n",
    "        prev_clean['AMT_APPLICATION'] / prev_clean['AMT_CREDIT'],\n",
    "        0\n",
    "    )\n",
    "\n",
    "    # Агрегация prev_app \n",
    "    prev_clean['APPROVED'] = (prev_clean['NAME_CONTRACT_STATUS'] == 'Approved').astype(int)\n",
    "\n",
    "    prev_agg = prev_clean.groupby('SK_ID_CURR').agg({\n",
    "        'AMT_CREDIT': ['mean', 'max', 'sum'],\n",
    "        'NAME_CONTRACT_STATUS': 'count',\n",
    "        'APPROVED': 'mean',\n",
    "        'APP_CREDIT_RATIO': 'mean',\n",
    "        'DAYS_DECISION': ['min', 'max']\n",
    "    })\n",
    "\n",
    "    prev_agg.columns = [\n",
    "        'PREV_CREDIT_MEAN', 'PREV_CREDIT_MAX', 'PREV_CREDIT_SUM',\n",
    "        'PREV_APP_COUNT', 'PREV_APPROVED_RATE',\n",
    "        'MEAN_APP_CREDIT_RATIO', 'EARLIEST_DECISION', 'LATEST_DECISION'\n",
    "    ]\n",
    "    prev_agg.reset_index(inplace=True)\n",
    "\n",
    "    # Объединение с app_data \n",
    "    df = app_data_clean.merge(prev_agg, on='SK_ID_CURR', how='left')\n",
    "\n",
    "    # Feature Engineering \n",
    "    def safe_divide(a, b):\n",
    "        return pd.Series(np.where(b != 0, a / b, 0), index=a.index)\n",
    "\n",
    "    df['INCOME_CREDIT_RATIO'] = safe_divide(df['AMT_CREDIT'], df['AMT_INCOME_TOTAL'])\n",
    "    df['ANNUITY_INCOME_RATIO'] = safe_divide(df['AMT_ANNUITY'], df['AMT_INCOME_TOTAL'])\n",
    "    df['WORK_EXPERIENCE_RATIO'] = safe_divide(-df['DAYS_EMPLOYED'] / 365, -df['DAYS_BIRTH'] / 365)\n",
    "    df['AGE'] = -df['DAYS_BIRTH'] / 365\n",
    "    df['DAYS_BETWEEN_APPS'] = df['LATEST_DECISION'] - df['EARLIEST_DECISION']\n",
    "    df['DEPENDENTS_RATIO'] = safe_divide(df['CNT_CHILDREN'], df['CNT_FAM_MEMBERS'])\n",
    "\n",
    "    df['EXT_SOURCE_COMBINED'] = (\n",
    "            df['EXT_SOURCE_1'].fillna(0) * 0.3 +\n",
    "            df['EXT_SOURCE_2'].fillna(0) * 0.5 +\n",
    "            df['EXT_SOURCE_3'].fillna(0) * 0.2\n",
    "    )\n",
    "\n",
    "    new_features = ['INCOME_CREDIT_RATIO', 'ANNUITY_INCOME_RATIO', 'WORK_EXPERIENCE_RATIO', 'DEPENDENTS_RATIO']\n",
    "    df = cap_outliers(df, new_features)\n",
    "\n",
    "    cols_to_drop = [\n",
    "        'DAYS_BIRTH', 'DAYS_EMPLOYED', 'FLAG_MOBIL', 'FLAG_EMP_PHONE',\n",
    "        'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "        'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'SK_ID_CURR'\n",
    "    ]\n",
    "    df.drop(columns=[col for col in cols_to_drop if col in df.columns], inplace=True)\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T22:19:25.821843Z",
     "start_time": "2025-06-06T22:19:25.815780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_log_features(X, cols):\n",
    "    for col in cols:\n",
    "        if col in X.columns:\n",
    "            X[f'{col}_LOG'] = np.log1p(X[col])\n",
    "    return X"
   ],
   "id": "28393fac4fb8b5b",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T22:19:28.625405Z",
     "start_time": "2025-06-06T22:19:28.609277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_best_threshold(y_true, y_proba):\n",
    "    prec, rec, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    f1_scores = 2 * (prec * rec) / (prec + rec + 1e-6)\n",
    "    best_idx = np.argmax(f1_scores)\n",
    "    return thresholds[best_idx], f1_scores[best_idx]\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_proba, threshold):\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    pr_auc = average_precision_score(y_true, y_proba)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f\"Threshold: {threshold:.2f} | ROC-AUC: {roc_auc:.4f} | PR-AUC: {pr_auc:.4f} | F1: {f1:.4f}\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    return roc_auc, pr_auc, f1\n",
    "\n",
    "\n",
    "def get_preprocessor(X, num_cols, cat_cols):\n",
    "    return ColumnTransformer(transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_cols)\n",
    "    ])"
   ],
   "id": "9ab88e83e6004f39",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T22:19:32.913439Z",
     "start_time": "2025-06-06T22:19:32.901900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cross_val_pipeline(X, y, model, num_cols, cat_cols=None, use_smote=False, use_onehot=False,\n",
    "                       preprocess_manually=False, verbose=True):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    roc_aucs, pr_aucs, f1s = [], [], []\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "        if verbose:\n",
    "            print(f\"\\nFold {fold}\")\n",
    "\n",
    "        X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        if cat_cols:\n",
    "            for col in cat_cols:\n",
    "                X_train[col] = X_train[col].astype(str).fillna(\"missing\")\n",
    "                X_test[col] = X_test[col].astype(str).fillna(\"missing\")\n",
    "        if preprocess_manually:\n",
    "            log_cols = [f'{c}_LOG' for c in ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY'] if\n",
    "                        f'{c}_LOG' in X_train.columns]\n",
    "            num_cols_full = list(set(num_cols) | set(log_cols))\n",
    "\n",
    "            preprocessor = ColumnTransformer(transformers=[\n",
    "                ('num', StandardScaler(), num_cols_full),\n",
    "                ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), cat_cols)\n",
    "            ])\n",
    "\n",
    "            X_train = preprocessor.fit_transform(X_train)\n",
    "            X_test = preprocessor.transform(X_test)\n",
    "\n",
    "        if use_onehot:\n",
    "            X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "            X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "            X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "        if use_smote:\n",
    "            sm = SMOTE(random_state=42)\n",
    "            X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "        clf = clone(model)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        threshold, best_f1 = compute_best_threshold(y_test, y_proba)\n",
    "        roc_auc, pr_auc, f1 = evaluate_model(y_test, y_proba, threshold)\n",
    "\n",
    "        roc_aucs.append(roc_auc)\n",
    "        pr_aucs.append(pr_auc)\n",
    "        f1s.append(f1)\n",
    "\n",
    "    print(\"\\n--- Средние метрики ---\")\n",
    "    print(f\"ROC-AUC: {np.mean(roc_aucs):.4f}\")\n",
    "    print(f\"PR-AUC: {np.mean(pr_aucs):.4f}\")\n",
    "    print(f\"F1-score: {np.mean(f1s):.4f}\")"
   ],
   "id": "265775d9ae5d67cd",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T22:19:48.540796Z",
     "start_time": "2025-06-06T22:19:37.323942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "app_data = pd.read_csv('application_data.csv')\n",
    "prev_app = pd.read_csv('previous_application.csv')"
   ],
   "id": "ad253d169793f595",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T22:20:00.032723Z",
     "start_time": "2025-06-06T22:19:54.835439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "app_data = app_data[app_data['TARGET'].isin([0, 1])]\n",
    "X = preprocess_data(app_data, prev_app)\n",
    "y = app_data['TARGET']"
   ],
   "id": "b9d0b8a76c8e2507",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "log_cols = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY']\n",
    "X_train_full = add_log_features(X_train_full, log_cols)\n",
    "\n",
    "num_cols = X_train_full.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X_train_full.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "models = {\n",
    "    'LogReg': Pipeline([\n",
    "        ('prep', get_preprocessor(X, num_cols, cat_cols)),\n",
    "        ('clf', LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'))\n",
    "    ]),\n",
    "    'Bagging+LogReg': BalancedBaggingClassifier(\n",
    "        estimator=LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'),\n",
    "        n_estimators=10, n_jobs=-1, random_state=42\n",
    "    ),\n",
    "\n",
    "    'XGBoost': XGBClassifier(\n",
    "        n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "        scale_pos_weight=(y == 0).sum() / (y == 1).sum(),\n",
    "        use_label_encoder=False, eval_metric='auc', n_jobs=-1, random_state=42\n",
    "    ),\n",
    "    'CatBoost': CatBoostClassifier(\n",
    "        iterations=300, learning_rate=0.05, depth=6,\n",
    "        eval_metric='AUC', verbose=0, random_seed=42\n",
    "    ),\n",
    "\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n========== {name} ==========\")\n",
    "    cross_val_pipeline(\n",
    "        X_train_full.copy(), y_train_full, model,\n",
    "        num_cols=num_cols,\n",
    "        cat_cols=cat_cols,\n",
    "        use_smote=False,\n",
    "        use_onehot=(name in ['XGBoost', 'CatBoost']),\n",
    "        preprocess_manually=(name == 'Bagging+LogReg'),\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\nОценка на тестовом наборе для {name}:\")\n",
    "\n",
    "    X_train_test = X_train_full.copy()\n",
    "    X_test_test = X_test.copy()\n",
    "    if name == 'LogReg':\n",
    "        X_train_test = X_train_full.copy()\n",
    "        X_test_test = X_test.copy()\n",
    "\n",
    "        log_cols = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY']\n",
    "        X_train_test = add_log_features(X_train_test, log_cols)\n",
    "        X_test_test = add_log_features(X_test_test, log_cols)\n",
    "\n",
    "        for col in cat_cols:\n",
    "            if col in X_train_test.columns:\n",
    "                X_train_test[col] = X_train_test[col].astype(str).fillna(\"missing\")\n",
    "                X_test_test[col] = X_test_test[col].astype(str).fillna(\"missing\")\n",
    "\n",
    "        required_cols = num_cols + [f'{c}_LOG' for c in log_cols] + cat_cols\n",
    "        missing_cols = set(required_cols) - set(X_train_test.columns)\n",
    "        if missing_cols:\n",
    "            print(f\"Предупреждение: отсутствуют столбцы {missing_cols}\")\n",
    "\n",
    "    elif name == 'Bagging+LogReg':\n",
    "        log_cols = ['AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY']\n",
    "        X_train_test = add_log_features(X_train_test, log_cols)\n",
    "        X_test_test = add_log_features(X_test_test, log_cols)\n",
    "\n",
    "        for col in cat_cols:\n",
    "            X_train_test[col] = X_train_test[col].astype(str).fillna(\"missing\")\n",
    "            X_test_test[col] = X_test_test[col].astype(str).fillna(\"missing\")\n",
    "\n",
    "        log_cols_final = [f'{c}_LOG' for c in log_cols if f'{c}_LOG' in X_train_test.columns]\n",
    "        num_cols_full = list(set(num_cols) | set(log_cols_final))\n",
    "\n",
    "        num_cols_full = [col for col in num_cols_full if col in X_train_test.columns]\n",
    "        valid_cat_cols = [col for col in cat_cols if col in X_train_test.columns]\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', StandardScaler(), num_cols_full),\n",
    "                ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), valid_cat_cols)\n",
    "            ],\n",
    "            remainder='drop'\n",
    "        )\n",
    "\n",
    "        X_train_test = preprocessor.fit_transform(X_train_test)\n",
    "        X_test_test = preprocessor.transform(X_test_test)\n",
    "\n",
    "    elif name in ['XGBoost', 'CatBoost']:\n",
    "        X_train_test = pd.get_dummies(X_train_test, columns=cat_cols)\n",
    "        X_test_test = pd.get_dummies(X_test_test, columns=cat_cols)\n",
    "\n",
    "        X_train_test, X_test_test = X_train_test.align(X_test_test, join='left', axis=1, fill_value=0)\n",
    "\n",
    "        X_train_test = X_train_test.values\n",
    "        X_test_test = X_test_test.values\n",
    "\n",
    "    final_model = clone(model)\n",
    "    final_model.fit(X_train_test, y_train_full)\n",
    "\n",
    "    y_proba_test = final_model.predict_proba(X_test_test)[:, 1]\n",
    "    thresh_test, _ = compute_best_threshold(y_test, y_proba_test)\n",
    "    evaluate_model(y_test, y_proba_test, thresh_test)"
   ],
   "id": "e7ec5058a4107042"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
